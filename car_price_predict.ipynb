{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Today I will train a model with multiple parameters that will predict car prices in the USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocess, preprocess_v2, preprocess_v22\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('C:\\Scripts\\PredictCarPrice\\data\\CarPrice_Assignment.csv')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this example, it seemed to me as if these data were normalized kind of together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\"horsepower\", \"doornumber\", \"peakrpm\", \"highwaympg\", \"citympg\", \"compressionratio\", \"stroke\", \"boreratio\", \"enginesize\", \"wheelbase\", \"price\",]\n",
    "\n",
    "features = preprocess(dataset.loc[:, lst])\n",
    "features.shape # мы увидим информацию о размерности нашего датафрейма \n",
    "features.info() # покажет информацию о размерности данных \n",
    "features.describe() # показывает статистики count,mean, std, min, 25%-50%-75% percentile, max \n",
    "# features.nunique() # количество уникальных значений для каждого столбца \n",
    "\n",
    "# features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.min()\n",
    "#  features.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So I decided to make a second version of the preprocess func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad try\n",
    "\n",
    "# from preprocess import preprocess_v22\n",
    "\n",
    "\n",
    "# features_v2 = preprocess_v22(dataset)\n",
    "# features_v2 = pd.DataFrame(features_v2) # покажет информацию о размерности данных \n",
    "# len(features_v2['wheelbase'])\n",
    "\n",
    "features['is_two'] = dataset['doornumber'].apply(lambda x: int(x == 'two'))\n",
    "\n",
    "\n",
    "two_DataSet = features.loc[features['is_two'] == 1]\n",
    "four_DataSet = features.loc[features['is_two'] == 0]\n",
    "\n",
    "print(len(two_DataSet))\n",
    "print(len(four_DataSet))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(features, [i for i in range(1, len(features)+1)], c=\"b\", label=\"Our Prediction\")\n",
    "# #  plt.scatter(x_train, y_train, marker=\"x\", c=\"r\", label=\"Actual price\")\n",
    "# plt.xlabel(\"Sixe\")\n",
    "# plt.ylabel(\"Price\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(two_DataSet['horsepower'], two_DataSet['price'], label=\"two doors\", c='Red')\n",
    "plt.scatter(four_DataSet['horsepower'], four_DataSet['price'], label=\"four doors\", c='Blue')\n",
    "plt.xlabel(\"horsepower\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(two_DataSet['highwaympg'], two_DataSet['price'], label=\"two doors\", c='Red')\n",
    "plt.scatter(four_DataSet['highwaympg'], four_DataSet['price'], label=\"four doors\", c='Blue')\n",
    "plt.xlabel(\"highwaympg\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(two_DataSet['citympg'], two_DataSet['price'], label=\"two doors\", c='Red')\n",
    "plt.scatter(four_DataSet['citympg'], four_DataSet['price'], label=\"four doors\", c='Blue')\n",
    "plt.xlabel(\"citympg\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(two_DataSet['stroke'], two_DataSet['price'], label=\"two doors\", c='Red')\n",
    "plt.scatter(four_DataSet['stroke'], four_DataSet['price'], label=\"four doors\", c='Blue')\n",
    "plt.xlabel(\"stroke\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(two_DataSet['boreratio'], two_DataSet['price'], label=\"two doors\", c='Red')\n",
    "plt.scatter(four_DataSet['boreratio'], four_DataSet['price'], label=\"four doors\", c='Blue')\n",
    "plt.xlabel(\"boreratio\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(two_DataSet['enginesize'], two_DataSet['price'], label=\"two doors\", c='Red')\n",
    "plt.scatter(four_DataSet['enginesize'], four_DataSet['price'], label=\"four doors\", c='Blue')\n",
    "plt.xlabel(\"enginesize\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(two_DataSet['wheelbase'], two_DataSet['price'], label=\"two doors\", c='Red')\n",
    "plt.scatter(four_DataSet['wheelbase'], four_DataSet['price'], label=\"four doors\", c='Blue')\n",
    "plt.xlabel(\"wheelbase\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiogram import filters\n",
    "\n",
    "\n",
    "train_df, val_test_df = train_test_split(features, train_size=0.6, random_state=0)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "print(train_df)\n",
    "\n",
    "train_target = train_df['price']\n",
    "train_X = train_df.loc[:,['horsepower', 'doornumber', 'peakrpm', 'highwaympg', 'citympg', 'compressionratio', 'stroke', 'boreratio', 'enginesize', 'wheelbase']]\n",
    "\n",
    "\n",
    "val_target = val_df['price']\n",
    "val_X = val_df.loc[:,['horsepower', 'doornumber', 'peakrpm', 'highwaympg', 'citympg', 'compressionratio', 'stroke', 'boreratio', 'enginesize', 'wheelbase']]\n",
    "\n",
    "test_target = test_df['price']\n",
    "test_X = test_df.loc[:,['horsepower', 'doornumber', 'peakrpm', 'highwaympg', 'citympg', 'compressionratio', 'stroke', 'boreratio', 'enginesize', 'wheelbase']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### part: train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "\n",
    "regressor.fit(train_X, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "regressor.coef_\n",
    "train_X, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(val_X)\n",
    "loss = np.abs(y_pred - val_target).mean() * 100\n",
    "print(f\"Процент ошибки: {loss:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### part: value "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "723d4b7bc280cd31fdada53ad6420192b9a3a8d60631096143cc718cb9440dc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
